{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Exceptions\n",
    "\n",
    "In this notebook, we'll explore how to handle exceptions effectively. Exception handling is crucial for building robust and maintainable code, especially in complex workflows. We'll cover best practices, demonstrate how to implement them in a data science context, and illustrate advanced techniques such as using custom exceptions and ensuring clean error handling across nested functions.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Basic Exception Handling](#1)\n",
    "2. [Custom Exceptions](#2)\n",
    "3. [Nested Functions and Exception Propagation](#3)\n",
    "4. [Logging Exceptions](#4)\n",
    "5. [Step-by-Step Example](#5)\n",
    "6. [Exercise](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Basic Exception Handling <a name=\"1\"></a>\n",
    "\n",
    "Exception handling allows your code to deal with errors gracefully. Here's a simple example of handling an exception in a data loading step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file at data/raw/non_existent_file.csv was not found.\n",
      "Hallo nach Exception!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data(filepath):\n",
    "    try:\n",
    "        data = pd.read_csv(filepath)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {filepath} was not found.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"Error: No data in file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Usage\n",
    "data = load_data('data/raw/non_existent_file.csv')\n",
    "\n",
    "print(\"Hallo nach Exception!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Custom Exceptions <a name=\"2\"></a>\n",
    "\n",
    "Creating custom exceptions allows you to handle specific error conditions more gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipelineError(Exception):\n",
    "    pass\n",
    "\n",
    "class DataValidationError(DataPipelineError):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Data validation failed.\")\n",
    "\n",
    "class MissingValuesError(DataPipelineError):\n",
    "    def __init__(self, missing_values):\n",
    "        self.missing_values = missing_values\n",
    "        super().__init__(\n",
    "            f\"Data contains {missing_values} missing values.\")\n",
    "\n",
    "# This function always raises an exception\n",
    "def validate_data(data):\n",
    "    missing_values = data.isnull().sum().sum()\n",
    "    if  missing_values > 0:\n",
    "        raise MissingValuesError(missing_values)\n",
    "    # else:\n",
    "    #     raise DataValidationError\n",
    "\n",
    "# Usage\n",
    "try:\n",
    "    data = load_data('../data/raw/train.csv') # Validation Error: Data validation failed.\n",
    "    #data = load_data('../data/raw/sample.csv') # Data contains 1 missing values.\n",
    "    validate_data(data)\n",
    "except MissingValuesError as e:\n",
    "    print(f\"Data contains {e.missing_values} missing values.\")\n",
    "except DataValidationError as e:\n",
    "    print(f\"Validation Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Nested Functions and Exception Propagation <a name=\"3\"></a>\n",
    "\n",
    "Handling exceptions in nested functions ensures that errors are caught and managed properly, preventing unexpected crashes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data validation failed: Missing column during preprocessing\n"
     ]
    },
    {
     "ename": "DataPreprocessingError",
     "evalue": "Missing column during preprocessing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/dsr-setup/lib/python3.12/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'existing_column'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Example preprocessing step\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_column\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexisting_column\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/dsr-setup/lib/python3.12/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "File \u001b[0;32m~/anaconda3/envs/dsr-setup/lib/python3.12/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'existing_column'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDataPreprocessingError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m processed_data \u001b[38;5;241m=\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/raw/train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     15\u001b[0m     data \u001b[38;5;241m=\u001b[39m load_data(filepath)\n\u001b[1;32m     16\u001b[0m     validate_data(data)\n\u001b[0;32m---> 17\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m DataPreprocessingError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataPreprocessingError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mDataPreprocessingError\u001b[0m: Missing column during preprocessing"
     ]
    }
   ],
   "source": [
    "class DataPreprocessingError(DataPipelineError):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Missing column during preprocessing\")\n",
    "\n",
    "def preprocess_data(data):\n",
    "    try:\n",
    "        # Example preprocessing step\n",
    "        data['new_column'] = data['existing_column'] * 2\n",
    "        return data\n",
    "    except KeyError as e:\n",
    "        raise DataPreprocessingError from e\n",
    "\n",
    "def run_pipeline(filepath):\n",
    "    try:\n",
    "        data = load_data(filepath)\n",
    "        validate_data(data)\n",
    "        data = preprocess_data(data)\n",
    "        return data\n",
    "    except DataPreprocessingError as e:\n",
    "        print(f\"Data validation failed: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred in the pipeline: {e}\")\n",
    "        raise\n",
    "\n",
    "# Usage\n",
    "processed_data = run_pipeline('../data/raw/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Logging Exceptions <a name=\"4\"></a>\n",
    "\n",
    "Using logging for exception handling provides a more flexible and powerful way to manage errors, especially in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:File not found: data/raw/non_existent_file.csv\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_85789/3190175182.py\", line 9, in load_data\n",
      "    data = pd.read_csv(filepath)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrbjoern/anaconda3/envs/dsr-setup/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 948, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrbjoern/anaconda3/envs/dsr-setup/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 611, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrbjoern/anaconda3/envs/dsr-setup/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1448, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrbjoern/anaconda3/envs/dsr-setup/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1705, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "                   ^^^^^^^^^^^\n",
      "  File \"/home/hrbjoern/anaconda3/envs/dsr-setup/lib/python3.12/site-packages/pandas/io/common.py\", line 863, in get_handle\n",
      "    handle = open(\n",
      "             ^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/raw/non_existent_file.csv'\n",
      "CRITICAL:__main__:Critical error occurred: [Errno 2] No such file or directory: 'data/raw/non_existent_file.csv'\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_data(filepath):\n",
    "    try:\n",
    "        data = pd.read_csv(filepath)\n",
    "        return data\n",
    "    except FileNotFoundError:                                       # Error message no. 1\n",
    "        logger.exception(f\"File not found: {filepath}\")             # Error message no. 2\n",
    "        raise\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logger.exception(\"No data in file.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "# Usage\n",
    "try:\n",
    "    data = load_data('data/raw/non_existent_file.csv')\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Critical error occurred: {e}\")                # Error message no. 4\n",
    "                                                                    # (no. 3 comes from the system, I guess) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Step-by-Step Example <a name=\"5\"></a>\n",
    "\n",
    "We'll now build a complete data science pipeline with exception handling at each step.\n",
    "\n",
    "We start with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data\n",
    "    \n",
    "def preprocess_data(data):\n",
    "    X = data.drop(columns=['target'])\n",
    "    y = data['target']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def pipeline(datapath='train.csv'):\n",
    "    # Step 1: Load the data\n",
    "    data = load_data('data.csv')\n",
    "\n",
    "    # Step 2: Preprocess the data\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(data)\n",
    "    \n",
    "    # Step 3: Train the model\n",
    "    model = train_model(X_train, y_train)\n",
    "\n",
    "    # Step 4: Evaluate the model\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    print(f\"Model Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Setup up the logger and create a custom parent Exception**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create parent exception class\n",
    "class ModelPipelineError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Step 2: Data Loading**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileMissingException(ModelPipelineError):\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        super().__init__(\n",
    "            f\"The file {self.filepath} couldn't be found.\")\n",
    "    \n",
    "def load_data(filepath):\n",
    "    try:\n",
    "        data = pd.read_csv(filepath)\n",
    "        return data\n",
    "    except FileNotFoundError as e:\n",
    "        raise FileMissingException(filepath) from e\n",
    "                # Was genau macht hier \"from\"?\n",
    "                # Wir wissen es nicht. ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetMissingException(ModelPipelineError):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"The target is missing in the dataset.\")\n",
    "\n",
    "def preprocess_data(data):\n",
    "    try:\n",
    "        if 'target' not in data.columns:\n",
    "            raise TargetMissingException\n",
    "        data = data.dropna()  # Handle missing values\n",
    "        X = data.drop(columns=['target'])\n",
    "        y = data['target']\n",
    "        return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    except KeyError as e:\n",
    "        raise TargetMissingException from e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainingException(ModelPipelineError):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"The model was provided non allowed values.\")\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    try:\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "    except ValueError as e:\n",
    "        raise ModelTrainingException from e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Evaluating the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluationException(ModelPipelineError):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"The evaluation of the mode failed.\")\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, predictions):\n",
    "    try:\n",
    "        predictions = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        print(f\"Model Mean Squared Error: {mse}\")\n",
    "    except Exception as e:\n",
    "        raise ModelEvaluationException from e "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Running the Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:A problem was found while preparing the data.\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_95697/2707544091.py\", line 7, in pipeline\n",
      "    X_train, X_test, y_train, y_test = preprocess_data(data)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_95697/2856827353.py\", line 8, in preprocess_data\n",
      "    raise TargetMissingException\n",
      "TargetMissingException: The target is missing in the dataset.\n"
     ]
    },
    {
     "ename": "TargetMissingException",
     "evalue": "The target is missing in the dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTargetMissingException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m         logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during model evaluation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/raw/train.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(datapath, predictions)\u001b[0m\n\u001b[1;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m load_data(datapath)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Step 2: Preprocess the data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Step 3: Train the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m train_model(X_train, y_train)\n",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TargetMissingException\n\u001b[1;32m      9\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdropna()  \u001b[38;5;66;03m# Handle missing values\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mTargetMissingException\u001b[0m: The target is missing in the dataset."
     ]
    }
   ],
   "source": [
    "def pipeline(datapath, predictions):\n",
    "    try:\n",
    "        # Step 1: Load the data\n",
    "        data = load_data(datapath)\n",
    "\n",
    "        # Step 2: Preprocess the data\n",
    "        X_train, X_test, y_train, y_test = preprocess_data(data)\n",
    "    \n",
    "        # Step 3: Train the model\n",
    "        model = train_model(X_train, y_train)\n",
    "\n",
    "        # Step 4: Evaluate the model\n",
    "        predictions = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        print(f\"Model Mean Squared Error: {mse}\")\n",
    "\n",
    "    except FileMissingException as e:\n",
    "        logger.exception(\"A problem was found while loading the data.\")\n",
    "        raise\n",
    "    except TargetMissingException as e:\n",
    "        logger.exception(\"A problem was found while preparing the data.\")\n",
    "        raise\n",
    "    except ModelTrainingException as e:\n",
    "        logger.exception(\"A problem was found while training the data.\")\n",
    "        raise\n",
    "    except ModelEvaluationException as e:\n",
    "        logger.exception(\"Error during model evaluation.\")\n",
    "        raise\n",
    "\n",
    "pipeline(\"../data/raw/train.csv\", predictions=None) # predictions? TODO: Nachlesen!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Exercise <a name=\"6\"></a>\n",
    "**Task**\n",
    "You are provided with a simple data science pipeline that loads data, validates it, preprocesses it, and trains a model. The pipeline currently does not have any exception handling. Your task is to:\n",
    " - Add exception handling to each step of the pipeline.\n",
    " - Use custom exceptions where appropriate.\n",
    " - Implement logging for all exceptions.\n",
    "\n",
    "**Initial Code**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data\n",
    "\n",
    "def validate_data(data):\n",
    "    if data.isnull().sum().sum() > 0:\n",
    "        print(\"Data contains missing values.\")\n",
    "\n",
    "def preprocess_data(data):\n",
    "    data['new_column'] = data['existing_column'] * 2\n",
    "    return data\n",
    "\n",
    "def train_model(data):\n",
    "    X = data[['new_column']]\n",
    "    y = data['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def run_pipeline(filepath):\n",
    "    data = load_data(filepath)\n",
    "    validate_data(data)\n",
    "    data = preprocess_data(data)\n",
    "    model = train_model(data)\n",
    "    return model\n",
    "\n",
    "# Usage\n",
    "model = run_pipeline('data/raw/example.csv')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Requirements\n",
    "- Handle file not found errors in load_data.\n",
    "- Raise a custom exception for validation errors in validate_data.\n",
    "- Handle missing column errors in preprocess_data.\n",
    "- Handle any errors during model training in train_model.\n",
    "- Log all exceptions with appropriate severity levels.\n",
    "\n",
    "Write your solution here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data\n",
    "\n",
    "def validate_data(data):\n",
    "    if data.isnull().sum().sum() > 0:\n",
    "        print(\"Data contains missing values.\")\n",
    "\n",
    "def preprocess_data(data):\n",
    "    data['new_column'] = data['existing_column'] * 2\n",
    "    return data\n",
    "\n",
    "def train_model(data):\n",
    "    X = data[['new_column']]\n",
    "    y = data['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def run_pipeline(filepath):\n",
    "    data = load_data(filepath)\n",
    "    validate_data(data)\n",
    "    data = preprocess_data(data)\n",
    "    model = train_model(data)\n",
    "    return model\n",
    "\n",
    "# Usage\n",
    "model = run_pipeline('data/raw/example.csv')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Solution**\n",
    "\n",
    "(careful, the solution is not correct, it's still being reviewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DataValidationError(Exception):\n",
    "    pass\n",
    "\n",
    "def load_data(filepath):\n",
    "    try:\n",
    "        data = pd.read_csv(filepath)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found: {filepath}\")\n",
    "        raise\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logger.error(\"No data in file.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "def validate_data(data):\n",
    "    try:\n",
    "        if data.isnull().sum().sum() > 0:\n",
    "            raise DataValidationError(\"Data contains missing values.\")\n",
    "    except DataValidationError as e:\n",
    "        logger.warning(f\"Validation error: {e}\")\n",
    "        raise\n",
    "\n",
    "def preprocess_data(data):\n",
    "    try:\n",
    "        data['new_column'] = data['existing_column'] * 2\n",
    "        return data\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Missing column during preprocessing: {e}\")\n",
    "        raise DataValidationError(f\"Preprocessing error: {e}\")\n",
    "\n",
    "def train_model(data):\n",
    "    try:\n",
    "        X = data[['new_column']]\n",
    "        y = data['target']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Missing target column: {e}\")\n",
    "        raise DataValidationError(f\"Training error: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during model training: {e}\")\n",
    "        raise\n",
    "\n",
    "def run_pipeline(filepath):\n",
    "    try:\n",
    "        data = load_data(filepath)\n",
    "        validate_data(data)\n",
    "        data = preprocess_data(data)\n",
    "        model = train_model(data)\n",
    "        return model\n",
    "    except DataValidationError as e:\n",
    "        logger.error(f\"Pipeline failed: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Critical error in pipeline: {e}\")\n",
    "\n",
    "# Usage\n",
    "try:\n",
    "    model = run_pipeline('data/raw/example.csv')\n",
    "    print(model)\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Pipeline execution failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Intro_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
